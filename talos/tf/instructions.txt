chmod +x cloudlab-setup-ubuntu-tl.sh && ./cloudlab-setup-ubuntu-tl.sh && \
sudo apt-get install libvirt-daemon genisoimage libguestfs-tools libosinfo-bin virtinst qemu-kvm git vim net-tools wget curl bash-completion python-pip libvirt-daemon-system virt-manager bridge-utils libnss-libvirt libvirt-clients osinfo-db-tools intltool sshpass p7zip-full p7zip-rar uvtool -y && \
sudo sed -i 's/hosts:          files dns/hosts:          files libvirt libvirt_guest dns/' /etc/nsswitch.conf && sudo lsmod | grep kvm && sudo reboot
#sudo systemctl restart libvirtd && sudo systemctl status libvirtd

screen
# Press Return to continue
# detach from session without killing it: Ctrl a d 
# to see screen sessions: screen -ls
# detach from closed session: screen -d -r 2018.pts-0.node0
# enter session: screen -r 2018.pts-0.node0
# exit a session and terminate it: exit

sudo -i

cd /mnt/extra && cat /sys/module/kvm_intel/parameters/nested && cat /proc/cpuinfo | awk '/^processor/{print $3}' | wc -l && free -h && df -hT && sudo virsh list --all && sudo brctl show && \
wget -O "/mnt/extra/osinfo-db.tar.xz" https://releases.pagure.org/libosinfo/osinfo-db-20250606.tar.xz && sudo osinfo-db-import --local "/mnt/extra/osinfo-db.tar.xz"

# Install dependencies
sudo apt update -y && sudo apt-get install apt-transport-https ca-certificates curl gnupg python3-venv -y && \
sudo usermod -aG libvirt `id -un` && sudo adduser `id -un` libvirt-qemu && sudo adduser `id -un` kvm && sudo adduser `id -un` libvirt-dnsmasq && sudo sed -i 's/0770/0777/' /etc/libvirt/libvirtd.conf && \
echo 0 | sudo tee /sys/module/kvm/parameters/halt_poll_ns && echo 'security_driver = "none"' | sudo tee /etc/libvirt/qemu.conf && sudo chmod 0644 /boot/vmlinuz* && \
sudo sed -i -E 's,#?(security_driver)\s*=.*,\1 = "none",g' /etc/libvirt/qemu.conf && \
sudo systemctl restart libvirtd && sudo apt-get install -y docker.io unzip && sudo usermod -aG libvirt $USER && sudo usermod -aG docker $USER && \
virsh pool-define-as default dir --target "/var/lib/libvirt/images" && virsh pool-build default && virsh pool-start default && virsh pool-autostart default && \
sudo systemctl status libvirtd

exit

sudo -i

virsh list --all && virsh net-list --all && virsh pool-list 

#################################################################################################################################
####################### Talos Linux Kubernetes cluster in libvirt QEMU/KVM Virtual Machines using terraform 
########################  https://github.com/rgl/terraform-libvirt-talos ########################  
#################################################################################################################################
#################################################################################################################################

### Getting the code
cd /mnt/extra && git clone --recurse-submodules -j4 https://github.com/rackerlabs/genestack /opt/genestack && sudo /opt/genestack/bootstrap.sh

#Install Terraform:
# see https://github.com/hashicorp/terraform/releases
# renovate: datasource=github-releases depName=hashicorp/terraform
wget 'https://releases.hashicorp.com/terraform/1.14.3/terraform_1.14.3_linux_amd64.zip' && \
unzip "terraform_1.14.3_linux_amd64.zip" && sudo install terraform /usr/local/bin && rm terraform terraform_*_linux_amd64.zip

#Install talosctl:
# see https://github.com/siderolabs/talos/releases
# renovate: datasource=github-releases depName=siderolabs/talos
talos_version='1.12.1' && wget https://github.com/siderolabs/talos/releases/download/v$talos_version/talosctl-linux-amd64 && \
sudo install talosctl-linux-amd64 /usr/local/bin/talosctl && rm talosctl-linux-amd64

#Install kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" && chmod +x kubectl && sudo mv kubectl /usr/local/bin

###Install the convert plugin
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl-convert" && \
sudo install -o root -g root -m 0755 kubectl-convert /usr/local/bin/kubectl-convert

###Install the ko plugin
curl -LO https://raw.githubusercontent.com/kubeovn/kube-ovn/release-1.12/dist/images/kubectl-ko && \
sudo install -o root -g root -m 0755 kubectl-ko /usr/local/bin/kubectl-ko

###Install yq
sudo wget https://github.com/mikefarah/yq/releases/download/v4.2.0/yq_linux_amd64.tar.gz -q -O - | tar xz && \
sudo mv yq_linux_amd64 /usr/local/bin/yq

###Install the convert plugin
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl-convert" && \
sudo install -o root -g root -m 0755 kubectl-convert /usr/local/bin/kubectl-convert

###Install the ko plugin
curl -LO https://raw.githubusercontent.com/kubeovn/kube-ovn/release-1.12/dist/images/kubectl-ko && \
sudo install -o root -g root -m 0755 kubectl-ko /usr/local/bin/kubectl-ko

###Install helm
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 && chmod 700 get_helm.sh && ./get_helm.sh

#Initialize terraform - Create the infrastructure:

cd /mnt/extra && git clone https://github.com/vpasias/clusterlab.git && cd /mnt/extra/clusterlab/talos/tf && chmod +x do && ./do init && sleep 5 && ./do plan-apply

#Show talos information:

export TALOSCONFIG=$PWD/talosconfig.yml && controllers="$(terraform output -raw controllers)" && workers="$(terraform output -raw workers)" && \
all="$controllers,$workers" && c0="$(echo $controllers | cut -d , -f 1)" && w0="$(echo $workers | cut -d , -f 1)" && talosctl -n $all version && talosctl -n $all dashboard

#Show kubernetes information:
export KUBECONFIG=$PWD/kubeconfig.yml && kubectl version && kubectl cluster-info && kubectl get nodes -o wide && kubectl get pods -o wide --all-namespaces

# Attach 2nd network interface to VMs
for i in {0..2}; do virsh attach-interface --domain athena_talos_c$i --type network --source service --model virtio --mac 02:00:aa:0a:01:1$i --config --live; done && \
for i in {0..2}; do virsh attach-interface --domain  athena_talos_w$i --type network --source service --model virtio --mac 02:00:aa:0a:01:2$i --config --live; done

###Install Kube OVN
#https://docs.rackspacecloud.com/k8s-cni-kube-ovn/#prerequisites

cat > /etc/genestack/helm-configs/kube-ovn/kube-ovn-helm-overrides.yaml <<EOF
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
---
global:
  registry:
    address: docker.io/kubeovn
    imagePullSecrets: []
networking:
  IFACE: eth0
  vlan:
    VLAN_INTERFACE_NAME: eth0
OPENVSWITCH_DIR: /var/lib/openvswitch
OVN_DIR: /var/lib/ovn
DISABLE_MODULES_MANAGEMENT: true
EOF

kubectl label node -l beta.kubernetes.io/os=linux kubernetes.io/os=linux && kubectl label node -l node-role.kubernetes.io/control-plane kube-ovn/role=master && \
kubectl label node -l ovn.kubernetes.io/ovs_dp_type!=userspace ovn.kubernetes.io/ovs_dp_type=kernel && sleep 5 && sudo /opt/genestack/bin/install-kube-ovn.sh

kubectl get subnets.kubeovn.io

###Deploy the Rook operator
#https://docs.rackspacecloud.com/storage-ceph-rook-internal/#talos-linux
# https://docs.siderolabs.com/kubernetes-guides/csi/ceph-with-rook

#helm repo add rook-release https://charts.rook.io/release
#helm install --create-namespace --namespace rook-ceph rook-ceph rook-release/rook-ceph
#kubectl label namespace rook-ceph pod-security.kubernetes.io/enforce=privileged
#helm install --create-namespace --namespace rook-ceph rook-ceph-cluster --set operatorNamespace=rook-ceph rook-release/rook-ceph-cluster
#kubectl --namespace rook-ceph get cephcluster rook-ceph

kubectl apply -k /etc/genestack/kustomize/rook-operator/base && sleep 5 && \
kubectl label node w0 role=storage-node && kubectl label node w1 role=storage-node && kubectl label node w2 role=storage-node

# Configure Rook-Ceph namespace with Talos privileged permissions
mkdir -p /etc/genestack/kustomize/rook-operator/overlay

cat > /etc/genestack/kustomize/rook-operator/overlay/namespace-talos.yaml <<EOF
apiVersion: v1
kind: Namespace
metadata:
  labels:
    kubernetes.io/metadata.name: rook-ceph
    pod-security.kubernetes.io/audit: privileged
    pod-security.kubernetes.io/audit-version: latest
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/enforce-version: latest
    pod-security.kubernetes.io/warn: privileged
    pod-security.kubernetes.io/warn-version: latest
  name: rook-ceph
EOF

cat > /etc/genestack/kustomize/rook-operator/overlay/kustomization.yaml <<EOF
sortOptions:
  order: fifo
resources:
  - namespace-talos.yaml
EOF

kubectl apply -k /etc/genestack/kustomize/rook-operator/overlay

sed -i 's/# deviceFilter: "^vd."/deviceFilter: sdb/g' /etc/genestack/kustomize/rook-cluster/base/rook-cluster.yaml

#Deploy the Rook cluster
kubectl apply -k /etc/genestack/kustomize/rook-cluster/overlay

#Validate the cluster is operational
kubectl --namespace rook-ceph get cephclusters.ceph.rook.io

kubectl --namespace rook-ceph get pods -w

#Create Storage Classes
kubectl apply -k /etc/genestack/kustomize/rook-defaults/base

kubectl -n rook-ceph patch CephCluster rook-ceph  --type=merge -p "{\"spec\": {\"monitoring\": {\"enabled\": true}}}"

#################################################################################################################################
### Troubleshoot ###
#################################################################################################################################

#Talos:
# see https://www.talos.dev/v1.2/advanced/troubleshooting-control-plane/

talosctl -n $c0 service etcd status
talosctl -n $c0 etcd members
talosctl -n $c0 get members
talosctl -n $c0 health --control-plane-nodes $controllers --worker-nodes $workers
talosctl -n $c0 dashboard
talosctl -n $c0 logs controller-runtime
talosctl -n $c0 logs kubelet
talosctl -n $c0 get disks
talosctl -n $c0 get links
talosctl -n $c0 get addresses
talosctl -n $c0 mounts | sort
talosctl -n $c0 get resourcedefinitions
talosctl -n $c0 get machineconfigs -o yaml
talosctl -n $c0 get staticpods -o yaml
talosctl -n $c0 get staticpodstatus
talosctl -n $c0 get manifests
talosctl -n $c0 get services
talosctl -n $c0 get extensions
talosctl -n $c0 get addresses
talosctl -n $c0 get nodeaddresses
talosctl -n $c0 list -l -r -t f /etc
talosctl -n $c0 list -l -r -t f /system
talosctl -n $c0 list -l -r -t f /var
talosctl -n $c0 list -l /sys/fs/cgroup
talosctl -n $c0 read /proc/cmdline | tr ' ' '\n'
talosctl -n $c0 read /proc/mounts | sort
talosctl -n $c0 read /etc/resolv.conf
talosctl -n $c0 read /etc/containerd/config.toml
talosctl -n $c0 read /etc/cri/containerd.toml
talosctl -n $c0 read /etc/cri/conf.d/cri.toml
talosctl -n $c0 read /etc/kubernetes/kubelet.yaml
talosctl -n $c0 read /etc/kubernetes/bootstrap-kubeconfig
talosctl -n $c0 ps
talosctl -n $c0 containers -k

#Kubernetes:

kubectl get events --all-namespaces --watch
kubectl --namespace kube-system get events --watch
kubectl run busybox -it --rm --restart=Never --image=busybox:1.36 -- nslookup -type=a talos.dev

#################################################################################################################################
### Delete Infrastructure ###
#################################################################################################################################

#cd /mnt/extra && rm -rf /mnt/extra/clusterlab 
#terraform destroy -auto-approve
cd /mnt/extra/clusterlab/talos/tf/ && ./do destroy && cd /mnt/extra && rm -rf /mnt/extra/clusterlab && virsh net-list && virsh list
virsh net-destroy service && virsh net-undefine service && \
virsh net-destroy athena_talos && virsh net-undefine athena_talos && \
virsh destroy athena_talos_c0 && \
virsh destroy athena_talos_c1 && \
virsh destroy athena_talos_c2 && \
virsh destroy athena_talos_w0 && \
virsh destroy athena_talos_w1 && \
virsh destroy athena_talos_w2 && \
virsh undefine athena_talos_c0 --nvram && \
virsh undefine athena_talos_c1 --nvram && \
virsh undefine athena_talos_c2 --nvram && \
virsh undefine athena_talos_w0 --nvram && \
virsh undefine athena_talos_w1 --nvram && \
virsh undefine athena_talos_w2 --nvram && \
virsh net-list && virsh list
